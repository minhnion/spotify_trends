{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6c8be2-10b4-4ceb-845a-12971193b12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42740c82-a420-4791-8547-52057462151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.11\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ba076a-8a12-490a-b0b8-a48875ab584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Äang quÃ©t táº¥t cáº£ file JSON trong bucket...\n",
      "ğŸ”¥ TÃ¬m tháº¥y vÃ  Ä‘á»c Ä‘Æ°á»£c: 100 file/dÃ²ng gá»‘c.\n",
      "ğŸ’¾ Cáº­p nháº­t láº¡i Data Lake (spotify_full_schema)...\n",
      "âœ… ÄÃ£ cáº­p nháº­t dá»¯ liá»‡u cÃ³ Ä‘áº§y Ä‘á»§ URI!\n",
      "root\n",
      " |-- pid: long (nullable = true)\n",
      " |-- playlist_name: string (nullable = true)\n",
      " |-- track_uri: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- artist_uri: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- album_uri: string (nullable = true)\n",
      " |-- album_name: string (nullable = true)\n",
      " |-- duration_ms: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, current_timestamp\n",
    "\n",
    "# 1. Config Spark\n",
    "JAR_PATH = \"/home/jovyan/jars\"\n",
    "jars = [f\"{JAR_PATH}/hadoop-aws-3.3.4.jar\", f\"{JAR_PATH}/aws-java-sdk-bundle-1.12.262.jar\"]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spotify Re-ETL\") \\\n",
    "    .config(\"spark.jars\", \",\".join(jars)) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Äá»c Raw Data (DÃ¹ng wildcard *)\n",
    "print(\"â³ Äang quÃ©t táº¥t cáº£ file JSON trong bucket...\")\n",
    "s3_path = \"s3a://spotify-raw-data/*.json\" # <--- Sá»¬A Lá»–I Táº I ÄÃ‚Y\n",
    "\n",
    "try:\n",
    "    df = spark.read.option(\"multiline\", \"true\").json(s3_path)\n",
    "    \n",
    "    # Kiá»ƒm tra xem cÃ³ Ä‘á»c Ä‘Æ°á»£c dÃ²ng nÃ o khÃ´ng\n",
    "    count = df.count()\n",
    "    print(f\"ğŸ”¥ TÃ¬m tháº¥y vÃ  Ä‘á»c Ä‘Æ°á»£c: {count} file/dÃ²ng gá»‘c.\")\n",
    "\n",
    "    # 3. Transform (Láº¥y Ä‘á»§ cá»™t theo Schema DB)\n",
    "    if \"playlists\" in df.columns:\n",
    "        tracks_df = df.select(explode(col(\"playlists\")).alias(\"p\")) \\\n",
    "            .select(\n",
    "                col(\"p.pid\").alias(\"pid\"),\n",
    "                col(\"p.name\").alias(\"playlist_name\"),\n",
    "                explode(col(\"p.tracks\")).alias(\"t\")\n",
    "            ).select(\n",
    "                col(\"pid\"), \n",
    "                col(\"playlist_name\"),\n",
    "                col(\"t.track_uri\"),\n",
    "                col(\"t.track_name\"),\n",
    "                col(\"t.artist_uri\"), # Quan trá»ng cho DB\n",
    "                col(\"t.artist_name\"),\n",
    "                col(\"t.album_uri\"),  # Quan trá»ng cho DB\n",
    "                col(\"t.album_name\"), \n",
    "                col(\"t.duration_ms\")\n",
    "            )\n",
    "\n",
    "        # 4. Ghi Ä‘Ã¨ láº¡i Parquet cÅ©\n",
    "        print(\"ğŸ’¾ Cáº­p nháº­t láº¡i Data Lake (spotify_full_schema)...\")\n",
    "        tracks_df.write.mode(\"overwrite\").parquet(\"s3a://warehouse/spotify_full_schema\")\n",
    "        print(\"âœ… ÄÃ£ cáº­p nháº­t dá»¯ liá»‡u cÃ³ Ä‘áº§y Ä‘á»§ URI!\")\n",
    "        \n",
    "        # In ra schema Ä‘á»ƒ báº¡n yÃªn tÃ¢m lÃ  cÃ³ Ä‘á»§ cá»™t\n",
    "        tracks_df.printSchema()\n",
    "    else:\n",
    "        print(\"âš ï¸ File JSON Ä‘á»c Ä‘Æ°á»£c nhÆ°ng khÃ´ng cÃ³ key 'playlists'. Kiá»ƒm tra láº¡i ná»™i dung file.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Váº«n lá»—i: {e}\")\n",
    "    # Máº¹o debug: Liá»‡t kÃª file xem thá»±c sá»± trong Ä‘Ã³ cÃ³ gÃ¬\n",
    "    print(\"ğŸ” Kiá»ƒm tra danh sÃ¡ch file trong bucket:\")\n",
    "    fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "    Path = spark._jvm.org.apache.hadoop.fs.Path\n",
    "    try:\n",
    "        files = fs.listStatus(Path(\"s3a://spotify-raw-data/\"))\n",
    "        for f in files:\n",
    "            print(f.getPath().toString())\n",
    "    except:\n",
    "        print(\"KhÃ´ng thá»ƒ liá»‡t kÃª file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8d643-d7aa-4377-95f0-aa50f7fa97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "# --- Cáº¤U HÃŒNH ---\n",
    "SUPABASE_URL = \"postgresql://postgres.xucnhlecthkbalouzymg:Nguyenminh21082004@aws-1-ap-southeast-1.pooler.supabase.com:6543/postgres\"\n",
    "parsed = urlparse(SUPABASE_URL)\n",
    "\n",
    "# URL JDBC cho Spark\n",
    "jdbc_url = f\"jdbc:postgresql://{parsed.hostname}:{parsed.port}{parsed.path}?prepareThreshold=0\"\n",
    "\n",
    "db_properties = {\n",
    "    \"user\": parsed.username,\n",
    "    \"password\": unquote(parsed.password),\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"sslmode\": \"require\"\n",
    "    # KhÃ´ng cáº§n thÃªm gÃ¬ vÃ o Ä‘Ã¢y ná»¯a\n",
    "}\n",
    "\n",
    "# --- PHáº¦N 1: Dá»ŒN Dáº¸P Dá»® LIá»†U CÅ¨ (QUAN TRá»ŒNG) ---\n",
    "print(\"ğŸ§¹ Äang dá»n sáº¡ch dá»¯ liá»‡u cÅ© trÃªn Cloud (Truncate)...\")\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=parsed.hostname, port=parsed.port, database=\"postgres\",\n",
    "        user=parsed.username, password=unquote(parsed.password), sslmode='require'\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    # DÃ¹ng CASCADE Ä‘á»ƒ xÃ³a dá»¯ liá»‡u á»Ÿ báº£ng con (playlist_tracks) trÆ°á»›c, rá»“i má»›i xÃ³a báº£ng cha\n",
    "    cur.execute(\"TRUNCATE TABLE playlist_tracks, tracks, playlists, albums, artists CASCADE;\")\n",
    "    conn.commit()\n",
    "    print(\"âœ… ÄÃ£ dá»n sáº¡ch database!\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Cáº£nh bÃ¡o dá»n dáº¹p: {e}\")\n",
    "\n",
    "# --- PHáº¦N 2: GHI Dá»® LIá»†U Má»šI ---\n",
    "print(\"â³ Äang Ä‘á»c dá»¯ liá»‡u Parquet...\")\n",
    "# Äá»c file vá»«a táº¡o á»Ÿ BÆ°á»›c 1\n",
    "full_df = spark.read.parquet(\"s3a://warehouse/spotify_full_schema\")\n",
    "\n",
    "# HÃ m ghi tiá»‡n Ã­ch\n",
    "def write_to_pg(df, table_name):\n",
    "    print(f\"ğŸ’¾ Äang ghi báº£ng '{table_name}' ({df.count()} dÃ²ng)...\")\n",
    "    df.write.jdbc(url=jdbc_url, table=table_name, mode=\"append\", properties=db_properties)\n",
    "    print(f\"   âœ… Xong báº£ng {table_name}\")\n",
    "\n",
    "try:\n",
    "    # 1. Ghi cÃ¡c báº£ng CHA trÆ°á»›c (Artists, Albums, Playlists)\n",
    "    # Báº£ng Artists\n",
    "    artists = full_df.select(\"artist_uri\", \"artist_name\").distinct()\n",
    "    write_to_pg(artists, \"artists\")\n",
    "\n",
    "    # Báº£ng Albums\n",
    "    albums = full_df.select(\"album_uri\", \"album_name\").distinct()\n",
    "    write_to_pg(albums, \"albums\")\n",
    "\n",
    "    # Báº£ng Playlists\n",
    "    playlists = full_df.select(\"pid\", \"playlist_name\").distinct()\n",
    "    write_to_pg(playlists, \"playlists\")\n",
    "\n",
    "    # 2. Ghi báº£ng TRACKS (Phá»¥ thuá»™c Artists & Albums)\n",
    "    # Chá»n Ä‘Ãºng cá»™t theo thá»© tá»± trong Schema DB\n",
    "    tracks = full_df.select(\"track_uri\", \"track_name\", \"artist_uri\", \"album_uri\", \"duration_ms\").distinct()\n",
    "    write_to_pg(tracks, \"tracks\")\n",
    "\n",
    "    # 3. Ghi báº£ng ná»‘i PLAYLIST_TRACKS (Phá»¥ thuá»™c Playlists & Tracks)\n",
    "   \n",
    "    # Sá»¬A Táº I ÄÃ‚Y: DÃ¹ng tháº³ng cá»™t \"pid\", khÃ´ng cáº§n alias\n",
    "    playlist_tracks = full_df.select(\n",
    "        col(\"pid\"), \n",
    "        col(\"track_uri\")\n",
    "    ).distinct()\n",
    "    \n",
    "    write_to_pg(playlist_tracks, \"playlist_tracks\")\n",
    "\n",
    "    print(\"\\nğŸ‰ CHÃšC Má»ªNG! Dá»¯ liá»‡u Ä‘Ã£ lÃªn mÃ¢y thÃ nh cÃ´ng!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Lá»—i khi ghi DB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7459b-8b23-4153-9d19-14fbe4713bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
